{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AID.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ehXSG3kjdXz",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KrJ4N2Cj0NF",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Function, Variable\n",
        "from torch import optim\n",
        "from torch.optim import *\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from pathlib import Path\n",
        "from torch.utils import data\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import cycle\n",
        "from torch.distributions.beta import Beta\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import time\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtSbZnB7jljD",
        "colab_type": "text"
      },
      "source": [
        "**Mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK7SzKB-jP-E",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/AIML_Project\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVUNhVUsj16-",
        "colab_type": "text"
      },
      "source": [
        "**Set arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmRPPDmyj6lV",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 50\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "LR = 1e-4\n",
        "DECAY_START = 23\n",
        "LMBDA = 0.1\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "ALPHA = 1.0\n",
        "EPS = 1e-16\n",
        "GAMMA = 0.1\n",
        "STEP_SIZE = 15\n",
        "\n",
        "PROJECT_PATH = str(Path(os.getcwd()))\n",
        "ARCHIVE_PATH = str(Path(PROJECT_PATH) / \"archives\")\n",
        "NPZ_PATH = str(Path(ARCHIVE_PATH) / \"NPZ\")\n",
        "CHECKPOINT_PATH = str(Path(ARCHIVE_PATH) / \"AwA2_checkpoints\")\n",
        "PATH_LAST = CHECKPOINT_PATH + '/last.pth'\n",
        "PATH_BEST = CHECKPOINT_PATH + '/best.pth'\n",
        "PATH_AUG = CHECKPOINT_PATH + '/augmix.pth.tar'\n",
        "\n",
        "DATA_DIR = 'Animals_with_Attributes2'\n",
        "\n",
        "train_classes = np.array(np.genfromtxt(DATA_DIR + '/trainclasses.txt', dtype='str'))\n",
        "classes = np.array(np.genfromtxt(DATA_DIR + '/classes.txt', dtype='str'))[:,-1]\n",
        "predicates = np.array(np.genfromtxt(DATA_DIR + '/predicates.txt', dtype='str'))[:,-1]\n",
        "predicate_binary_mat = np.array(np.genfromtxt(DATA_DIR + '/predicate-matrix-binary.txt', dtype='int'))\n",
        "num_labels = len(predicates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHnsYJBn4VTw",
        "colab_type": "text"
      },
      "source": [
        "**Plot functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUzvQDfF_YMD",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def imshow(image, title=None):\n",
        "  image = image.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image = std * image + mean\n",
        "  image = np.clip(image, 0, 1)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(image)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.axis('off')\n",
        "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "  plt.show()\n",
        "\n",
        "def little_imshow(image, title=None):\n",
        "  image = image.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  image = std * image + mean\n",
        "  image = np.clip(image, 0, 1)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(image)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.axis('off')\n",
        "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "  plt.show()\n",
        "\n",
        "def show_image_with_attributes(img):\n",
        "  preds = predicates\n",
        "  image = img['image'].cpu()\n",
        "  pred_label = img['pred_label'].cpu()\n",
        "  label = img['label'].cpu()\n",
        "  attributes_pred = img['pred_attr'].cpu()\n",
        "  attributes = img['attr'].cpu()\n",
        "  preds_attributes = []\n",
        "  colours_matrix = []\n",
        "\n",
        "  for i in range(85):\n",
        "    if attributes[i] == attributes_pred[i]:\n",
        "      preds_attributes.append(preds[i] + ': ' + str(int(attributes_pred[i])) + '/' + str(int(attributes[i])))\n",
        "      colours_matrix.append(['green'])\n",
        "    else:\n",
        "      preds_attributes.append(preds[i] + ': ' + str(int(attributes_pred[i])) + '/' + str(int(attributes[i])))\n",
        "      colours_matrix.append(['red'])\n",
        "  for i in range(5):\n",
        "    preds_attributes.append('')\n",
        "    colours_matrix.append(['white'])\n",
        "\n",
        "  preds_attributes = np.array(preds_attributes)\n",
        "  preds_attributes = preds_attributes.reshape(9,10)\n",
        "  colours_matrix = np.array(colours_matrix)\n",
        "  colours_matrix = colours_matrix.reshape(9,10)\n",
        "\n",
        "  df = pd.DataFrame(preds_attributes.reshape(9, 10))\n",
        "\n",
        "  fig = plt.figure(figsize=(20,4))\n",
        "  grid = plt.GridSpec(1, 5, wspace=0.0, hspace=0.0)\n",
        "  fig.suptitle(\"Random image vs grid of attributes (green = match, red = mismatch) and labels\")\n",
        "\n",
        "  ax1 = plt.subplot(grid[0, 0])\n",
        "  out = image.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  out = std * out + mean\n",
        "  out = np.clip(out, 0, 1)\n",
        "  plt.axis('off')\n",
        "  plt.subplots_adjust(hspace=0, wspace=1)\n",
        "  plt.imshow(out)\n",
        "\n",
        "  ax2 = plt.subplot(grid[0, 1:])\n",
        "  font_size=9\n",
        "  bbox=[0, 0, 1, 1]\n",
        "  ax2.axis('off')\n",
        "  mpl_table = ax2.table(cellText = df.values, bbox=bbox, cellLoc='left', cellColours=colours_matrix)\n",
        "  mpl_table.auto_set_font_size(False)\n",
        "  mpl_table.set_fontsize(font_size)\n",
        "  \n",
        "  plt.show()\n",
        "  print('Predicted class: {}'.format(classes[pred_label.item()]))\n",
        "  print('True class: {}'.format(classes[label.item()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9OEiLVskRQ0",
        "colab_type": "text"
      },
      "source": [
        "**Data Augmentations (AugMix)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1nMdJukWZ6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  return int(level * maxval / 10)\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  return float(level) * maxval / 10.\n",
        "\n",
        "def sample_level(n):\n",
        "  return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "  return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "  return ImageOps.equalize(pil_img)\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 4)\n",
        "  return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "  degrees = int_parameter(sample_level(level), 30)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    degrees = -degrees\n",
        "  return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 256)\n",
        "  return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE), Image.AFFINE, (1, level, 0, 0, 1, 0), resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE), Image.AFFINE, (1, 0, 0, level, 1, 0), resample=Image.BILINEAR)\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE), Image.AFFINE, (1, 0, level, 0, 1, 0), resample=Image.BILINEAR)\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE), Image.AFFINE, (1, 0, 0, 0, 1, level), resample=Image.BILINEAR)\n",
        "\n",
        "def color(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "  return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "def contrast(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "  return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "def brightness(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "  return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "def sharpness(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "  return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "augmentations_all = [autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y, translate_x, translate_y, color, contrast, brightness, sharpness]\n",
        "aug_list = augmentations_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3b9udItlD_U",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBcbOmaZlHpc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "MEAN = (0.4665, 0.4589, 0.3968)\n",
        "STD = (0.2454, 0.2356, 0.2443)\n",
        "\n",
        "standard_preprocess = transforms.Compose([\n",
        "  transforms.Resize(256), \n",
        "  transforms.CenterCrop(224),    \n",
        "])\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "aug_prob_coeff = 1. # Probability distribution coefficients\n",
        "mixture_width = 3 # Number of augmentation chains to mix per augmented example\n",
        "mixture_depth = -1 # Depth of augmentation chains. -1 denotes stochastic depth in [1, 3]\n",
        "aug_severity = 1 # Severity of base augmentation operators\n",
        "\n",
        "def aug(image, preprocess):\n",
        "  ws = np.float32(np.random.dirichlet([aug_prob_coeff] * mixture_width))\n",
        "  m = np.float32(np.random.beta(aug_prob_coeff, aug_prob_coeff))\n",
        "\n",
        "  mix = torch.zeros_like(preprocess(image))\n",
        "  for i in range(mixture_width):\n",
        "    image_aug = image.copy()\n",
        "    depth = mixture_depth if mixture_depth > 0 else np.random.randint(1, 4)\n",
        "    for _ in range(depth):\n",
        "      op = np.random.choice(aug_list)\n",
        "      image_aug = op(image_aug, aug_severity)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image_aug)\n",
        "\n",
        "  mixed = (1 - m) * preprocess(image) + m * mix\n",
        "  return mixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KivdRN_-lFUw",
        "colab_type": "text"
      },
      "source": [
        "**Dataset & dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aFMYYvzzoHN",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class AnimalDataset(data.dataset.Dataset):\n",
        "  def __init__(self, classes_file, transform=None):\n",
        "    predicate_binary_mat = np.array(np.genfromtxt(DATA_DIR + '/predicate-matrix-binary.txt', dtype='int'))\n",
        "    self.predicate_binary_mat = predicate_binary_mat\n",
        "    self.transform = transform\n",
        "\n",
        "    class_to_index = dict()\n",
        "    # Build dictionary of indices to classes\n",
        "    with open(DATA_DIR + '/classes.txt') as f:\n",
        "      index = 0\n",
        "      for line in f:\n",
        "        class_name = line.split('\\t')[1].strip()\n",
        "        class_to_index[class_name] = index\n",
        "        index += 1\n",
        "    self.class_to_index = class_to_index\n",
        "\n",
        "    img_names = []\n",
        "    img_index = []\n",
        "    \n",
        "    with open(('{}').format(classes_file)) as f:\n",
        "      for line in f:\n",
        "        class_name = line.split('\\t')[1].strip()\n",
        "        FOLDER_DIR = os.path.join(DATA_DIR + '/JPEGImages', class_name)\n",
        "        file_descriptor = os.path.join(FOLDER_DIR, '*.jpg')\n",
        "        files = glob(file_descriptor)\n",
        "\n",
        "        class_index = class_to_index[class_name]\n",
        "        for file_name in files:\n",
        "          img_names.append(file_name)\n",
        "          img_index.append(class_index)\n",
        "    self.img_names = img_names\n",
        "    self.img_index = img_index\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    im = Image.open(self.img_names[index])\n",
        "    if im.getbands()[0] == 'L':\n",
        "      im = im.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      im = self.transform(im)\n",
        "\n",
        "    im_index = self.img_index[index]\n",
        "    im_predicate = self.predicate_binary_mat[im_index,:]\n",
        "    return im, im_predicate, im_index\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "\n",
        "class WrapDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, preprocess, augmix=False):\n",
        "    self.dataset = dataset\n",
        "    self.preprocess = preprocess\n",
        "    self.augmix = augmix\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y, z = self.dataset[i]\n",
        "    if self.augmix:\n",
        "      flip = transforms.Compose([transforms.RandomHorizontalFlip()])\n",
        "      x = flip(x)\n",
        "      return aug(x, self.preprocess), y, z\n",
        "    else:\n",
        "      return self.preprocess(x), y, z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "\n",
        "def prepare_dataloaders(labeled_dataset, unlabeled_dataset, test_dataset, ind_dataset, batch_size):\n",
        "  dataloaders = {}\n",
        "  \n",
        "  dataloaders['labeled_dataloader'] = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
        "  dataloaders['unlabeled_dataloader'] = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
        "  dataloaders['val_dataloader'] = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=4)\n",
        "  dataloaders['ind_dataloader'] = DataLoader(ind_dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=4)\n",
        "  \n",
        "  return dataloaders\n",
        "\n",
        "print('Loading dataset...')\n",
        "all_dataset = AnimalDataset(DATA_DIR + '/classes.txt', standard_preprocess)\n",
        "print('Dataset loaded.')\n",
        "\n",
        "# Check dataset sizes\n",
        "print('All Dataset: {}'.format(len(all_dataset)))\n",
        "\n",
        "train_indexes = [idx for idx in range(len(all_dataset)) if idx % 2]\n",
        "test_indexes = [idx for idx in range(len(all_dataset)) if not idx % 10]\n",
        "ind_indexes = [idx for idx in range(len(all_dataset)) if not idx % 2]\n",
        "ind_indexes = [idx for idx in ind_indexes if idx not in test_indexes]\n",
        "ind_indexes = [idx for idx in range(len(ind_indexes)) if not idx % 8]\n",
        "train_dataset = Subset(all_dataset, train_indexes)\n",
        "test_dataset = Subset(all_dataset, test_indexes)\n",
        "test_dataset = WrapDataset(test_dataset, preprocess)\n",
        "ind_dataset = Subset(all_dataset, ind_indexes)\n",
        "ind_dataset = WrapDataset(ind_dataset, preprocess)\n",
        "labeled_indexes = [idx for idx in range(len(train_dataset)) if not idx % 2]\n",
        "labeled_indexes = [idx for idx in labeled_indexes if not idx % 3]\n",
        "labeled_dataset = Subset(train_dataset, labeled_indexes)\n",
        "labeled_dataset =  WrapDataset(labeled_dataset, preprocess, augmix=True)\n",
        "unlabeled_dataset = WrapDataset(train_dataset, preprocess, augmix=True)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('labeled Dataset: {}'.format(len(labeled_dataset)))\n",
        "print('unlabeled Dataset: {}'.format(len(unlabeled_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "print('Ind Dataset: {}'.format(len(ind_dataset)))\n",
        "\n",
        "dataloaders = prepare_dataloaders(labeled_dataset, unlabeled_dataset, test_dataset, ind_dataset, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkgcC34V0DxA",
        "colab_type": "text"
      },
      "source": [
        "**ADA-Net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6OcUIuZ0EP0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "class ReverseLayerF(Function):\n",
        "  @staticmethod\n",
        "  def forward(ctx, x, alpha):\n",
        "    ctx.alpha = alpha\n",
        "    return x.view_as(x)\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    output = grad_output.neg() * ctx.alpha\n",
        "    return output, None\n",
        "\n",
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n",
        "        nn.init.kaiming_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "resnet_dict = {\"ResNet18\":models.resnet18, \"ResNet34\":models.resnet34, \"ResNet50\":models.resnet50, \"ResNet101\":models.resnet101, \"ResNet152\":models.resnet152}\n",
        "\n",
        "class ResNetFc(nn.Module):\n",
        "  def __init__(self, resnet_name=\"ResNet50\", pretrained=False, augmix=True, bottleneck_dim=256, class_num=50, attr_num=85):\n",
        "    super(ResNetFc, self).__init__()\n",
        "    model_resnet = resnet_dict[resnet_name]() #(pretrained=pretrained)\n",
        "    if pretrained:\n",
        "      state_dict = torch.load(CHECKPOINT_PATH + \"/\" + resnet_name + \".pth\")\n",
        "      model_resnet.load_state_dict(state_dict)\n",
        "    if augmix:\n",
        "      state_dict = torch.load(PATH_AUG)['state_dict']\n",
        "      state_dict = {k[len('module.'):]: state_dict[k] for k, _ in state_dict.items()}\n",
        "      model_resnet.load_state_dict(state_dict)\n",
        "    self.lambd = 0.0\n",
        "    self.conv1 = model_resnet.conv1\n",
        "    self.bn1 = model_resnet.bn1\n",
        "    self.relu = model_resnet.relu\n",
        "    self.maxpool = model_resnet.maxpool\n",
        "    self.layer1 = model_resnet.layer1\n",
        "    self.layer2 = model_resnet.layer2\n",
        "    self.layer3 = model_resnet.layer3\n",
        "    self.layer4 = model_resnet.layer4\n",
        "    self.avgpool = model_resnet.avgpool\n",
        "    self.feature_layers = nn.Sequential(self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2, self.layer3, self.layer4, self.avgpool)\n",
        "\n",
        "    self.bottleneck = nn.Linear(model_resnet.fc.in_features, bottleneck_dim)\n",
        "    self.fc_attr = nn.Linear(bottleneck_dim, attr_num)\n",
        "    self.fc_class = nn.Linear(bottleneck_dim, class_num)\n",
        "\n",
        "    self.bottleneck.apply(init_weights)\n",
        "    self.fc_attr.apply(init_weights)\n",
        "    self.fc_class.apply(init_weights)\n",
        "    self.__in_features = bottleneck_dim\n",
        "    \n",
        "    self.discriminator = nn.Sequential(\n",
        "      nn.Linear(bottleneck_dim, 1024),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(1024, 1024),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(1024, 2),\n",
        "      nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def update_lambda(self, x):\n",
        "    self.lambd = 1.0 * (2. / (1. + np.exp(-10 * (x))) - 1.)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature_layers(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.bottleneck(x)\n",
        "    reverse_feature = ReverseLayerF().apply(x, self.lambd)\n",
        "    domain_output = self.discriminator(reverse_feature)\n",
        "    attribute_output = self.fc_attr(x)\n",
        "    class_output = self.fc_class(x)\n",
        "    # only class_output is passed through the softmax\n",
        "    return class_output, attribute_output, domain_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6lFzGw-59VH",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVGefVmX6AZu",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def train_Ada_Net(model, dataloaders, optimizer, scheduler, criterions, num_epochs=NUM_EPOCHS, decay_start=DECAY_START):\n",
        "  \n",
        "  labeled_dataloader = dataloaders['labeled_dataloader']\n",
        "  unlabeled_dataloader = dataloaders['unlabeled_dataloader']\n",
        "  val_dataloader = dataloaders['val_dataloader']\n",
        "  start_epoch = 1  # whether 1 or loaded from the checkpoint.\n",
        "  best_accuracy = -1.0\n",
        "  \n",
        "  if Path(PATH_LAST).exists():\n",
        "    model, optimizer, start_epoch = load_checkpoint('last', model, optimizer)\n",
        "  \n",
        "  if Path(PATH_BEST).exists():\n",
        "    best_accuracy = load_checkpoint('best', model, optimizer)\n",
        "  \n",
        "  for epoch in range(start_epoch, num_epochs+1):\n",
        "    print('\\n\\nEpoch [{}/{}]'.format(epoch, num_epochs), flush=True)\n",
        "    if decay_start:\n",
        "      if epoch > decay_start:\n",
        "        for g in optimizer.param_groups:\n",
        "          decayed_lr = (num_epochs - epoch) * g['lr'] / (num_epochs - decay_start)\n",
        "          g['lr'] = decayed_lr\n",
        "          g['betas'] = (0.5, 0.999) # reducing the momentum coefficient in the end of training can improve convergence\n",
        "\n",
        "    model = train_loop(model, labeled_dataloader, unlabeled_dataloader, optimizer, criterions, epoch)\n",
        "\n",
        "    attribute_accuracy, current_accuracy = eval_loop(model, val_dataloader)\n",
        "    \n",
        "    if current_accuracy > best_accuracy:\n",
        "      best_accuracy = current_accuracy\n",
        "      save_checkpoint('best', epoch, model, _, best_accuracy)\n",
        "  \n",
        "    scheduler.step()\n",
        "    \n",
        "    model.update_lambda(float((epoch)/num_epochs))\n",
        "\n",
        "    save_checkpoint('last', epoch, model, optimizer, _)\n",
        "\n",
        "def save_checkpoint(mode, epoch, model, optimizer, accuracy):\n",
        "  if mode == 'last':\n",
        "    torch.save({'epoch': epoch, \n",
        "              'model_state_dict': model.state_dict(), \n",
        "              'optimizer_state_dict': optimizer.state_dict()\n",
        "              }, PATH_LAST)\n",
        "  if mode == 'best':\n",
        "    torch.save({'epoch': epoch, \n",
        "            'model_state_dict': model.state_dict(), \n",
        "            'best_accuracy': accuracy\n",
        "            }, PATH_BEST)\n",
        "      \n",
        "def load_checkpoint(mode, model, optimizer):\n",
        "  if mode == 'last':\n",
        "    checkpoint = torch.load(PATH_LAST)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print('Loaded checkpoint at epoch {}'.format(start_epoch-1))\n",
        "    return model, optimizer, start_epoch\n",
        "  if mode == 'best':\n",
        "    checkpoint = torch.load(PATH_BEST)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    best_epoch = checkpoint['epoch']\n",
        "    print('Loaded checkpoint of best model at epoch {}'.format(best_epoch))\n",
        "    return best_accuracy\n",
        "\n",
        "def train_loop(model, labeled_dataloader, unlabeled_dataloader, optimizer, criterions, epoch, lmbda=LMBDA):\n",
        "  batch_num = tqdm(range(len(unlabeled_dataloader)), position=0, leave=True)\n",
        "  labeled_dataloader = cycle(labeled_dataloader)\n",
        "  unlabeled_dataloader = iter(unlabeled_dataloader)\n",
        "  \n",
        "  running_corrects = 0\n",
        "\n",
        "  for i in batch_num:\n",
        "    labeled_images, attributes, labels = next(labeled_dataloader)\n",
        "    unlabeled_images, _, _ = next(unlabeled_dataloader)\n",
        "    labeled_images, attributes, labels = labeled_images.to(DEVICE), attributes.to(DEVICE).float(), labels.to(DEVICE)\n",
        "    unlabeled_images = unlabeled_images.to(DEVICE)\n",
        "    model.train()\n",
        "\n",
        "    pred_labels, pred_attributes, _ = model(labeled_images)\n",
        "\n",
        "    running_corrects += torch.sum(pred_labels.max(1)[1] == labels.data)\n",
        "    batch_acc = running_corrects.double() / (len(labeled_images)*(i+1)) \n",
        "\n",
        "    class_loss = criterions['class'](pred_labels, labels)\n",
        "    sigmoid_attr_outputs = torch.sigmoid(pred_attributes)\n",
        "    attr_loss = criterions['attr'](sigmoid_attr_outputs, attributes)\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      pseudo_labels, _, _ = model(unlabeled_images)\n",
        "    model.train()\n",
        "    pseudo_labels = F.softmax(pseudo_labels, 1)\n",
        "\n",
        "    # generate mixed inputs, two one-hot label vectors and mixing coefficient\n",
        "    #mixed_images, mixed_labels, mixed_indexes = mixup_data(labeled_images, labels, unlabeled_images, pseudo_labels)\n",
        "    mixed_images, mixed_labels, mixed_indexes = cutmix_data(labeled_images, labels, unlabeled_images, pseudo_labels)\n",
        "\n",
        "    pred_labels_mixed, _, pred_domains_mixed = model(mixed_images)\n",
        "    pred_labels_mixed = F.softmax(pred_labels_mixed, 1)\n",
        "    class_loss_mixed = criterions['mixed'](pred_labels_mixed, mixed_labels)\n",
        "\n",
        "    domain_loss_mixed = criterions['mixed'](pred_domains_mixed, mixed_indexes)\n",
        "    mixed_loss = (class_loss_mixed + domain_loss_mixed) * 0.3\n",
        "    \n",
        "    total_loss = class_loss + attr_loss + mixed_loss\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_num.set_postfix({'class_loss': class_loss.item(),\n",
        "                           'attr_loss': attr_loss.item(),\n",
        "                           'class_loss_mixed': class_loss_mixed.item(),\n",
        "                           'domain_loss_mixed': domain_loss_mixed.item(),\n",
        "                           'total_loss': total_loss.item(),\n",
        "                           'train_acc': batch_acc.item()})\n",
        "  return model\n",
        "\n",
        "def eval_loop(model, _val_dataloader): \n",
        "  model.eval()\n",
        "  batch_num = tqdm(range(len(_val_dataloader)), position=0, leave=True)\n",
        "  val_dataloader = iter(_val_dataloader)\n",
        "  running_corrects_top1 = 0\n",
        "  running_corrects_top5 = 0\n",
        "  \n",
        "  num_elements = 0\n",
        "  running_correct_attributes = torch.Tensor([]).to(DEVICE)\n",
        "  running_attr_outputs = torch.Tensor([]).to(DEVICE)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    i = randint(0, len(val_dataloader)-2)\n",
        "    y = randint(0, BATCH_SIZE-1)\n",
        "    for val_batch_num in batch_num:\n",
        "      val_images, val_attributes, val_labels = next(val_dataloader)\n",
        "      val_images, val_attributes, val_labels = val_images.to(DEVICE), val_attributes.to(DEVICE).float(), val_labels.to(DEVICE)\n",
        "      val_pred_labels, val_pred_attributes, _ = model(val_images)\n",
        "\n",
        "      attr_outputs = (torch.sigmoid(val_pred_attributes) > 0.5).float()\n",
        "\n",
        "      running_correct_attributes =  torch.cat((running_correct_attributes, val_attributes), 0)\n",
        "      running_attr_outputs =  torch.cat((running_attr_outputs, attr_outputs), 0)\n",
        "\n",
        "      attr_score = hamming_score(running_correct_attributes.cpu(), running_attr_outputs.cpu())\n",
        "\n",
        "      _, preds = torch.max(val_pred_labels.data, 1)\n",
        "\n",
        "      running_corrects_top1 += torch.sum(preds == val_labels.data).data.item()\n",
        "\n",
        "      preds_top5 = torch.topk(val_pred_labels, 5)\n",
        "      indices_labels = preds_top5.indices\n",
        "\n",
        "      for j in range(BATCH_SIZE):\n",
        "        if val_labels[j] in indices_labels[j]:\n",
        "          running_corrects_top5 += 1\n",
        "\n",
        "      num_elements += len(val_images)\n",
        "      corrects_top1 = running_corrects_top1 / float(num_elements)\n",
        "      corrects_top5 = running_corrects_top5 / float(num_elements)\n",
        "      batch_num.set_postfix({'top1_acc': corrects_top1,\n",
        "                             'top5_acc': corrects_top5,\n",
        "                             'hamming score': attr_score})\n",
        "      \n",
        "      if val_batch_num == i:\n",
        "        r_img = {}\n",
        "        r_img['image'] = val_images[y]\n",
        "        r_img['pred_label'] = preds[y]\n",
        "        r_img['label'] = val_labels[y]\n",
        "        r_img['pred_attr'] = attr_outputs[y]\n",
        "        r_img['attr'] = val_attributes[y]\n",
        "\n",
        "  show_image_with_attributes(r_img)\n",
        "  \n",
        "  accuracy = running_corrects_top1 / float(len(_val_dataloader.dataset))\n",
        "  return attr_score, accuracy\n",
        "\n",
        "\n",
        "def mixup_data(labeled_images, labels, unlabeled_images, pseudo_labels):\n",
        "  '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
        "  beta = Beta(torch.tensor([ALPHA]), torch.tensor([ALPHA])) # defining the Beta distribution\n",
        "  batch_size, *shape = labeled_images.shape # splitting into batch size and image dimensions\n",
        "  lam = beta.sample((batch_size,)).squeeze(1).to(DEVICE) # sampling 256 samples from the Beta distribution\n",
        "  _lam = lam.view(batch_size, 1, 1, 1).repeat(1, *shape) # transform each of the 256 lamdas into a tensor of the image dimensions size\n",
        "\n",
        "  zeros_onehot = torch.zeros(batch_size, NUM_CLASSES, dtype=float).to(DEVICE)\n",
        "  labels_onehot = zeros_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "  mixed_images = _lam * labeled_images + (1 - _lam) * unlabeled_images # generate random mixed input image\n",
        "  mixed_labels = lam.view(batch_size, 1) * labels_onehot + (1 - lam).view(batch_size, 1) *  pseudo_labels # generate random mixed labels\n",
        "  mixed_indexes = torch.stack([lam, 1 - lam], dim=1).to(DEVICE) # stacked vector of the 2 lambdas for each batch (batch_num images per batch)\n",
        "\n",
        "  return mixed_images, mixed_labels, mixed_indexes\n",
        "\n",
        "def cutmix_data(labeled_images, labels, unlabeled_images, pseudo_labels):\n",
        "  '''Compute the mixcut data. Return mixed inputs, pairs of targets, and lambda'''\n",
        "  beta = Beta(torch.tensor([ALPHA]), torch.tensor([ALPHA])) # defining the Beta distribution\n",
        "  batch_size, *shape = labeled_images.shape # splitting into batch size and image dimensions\n",
        "  lam = beta.sample((batch_size,)).squeeze(1) #.to(DEVICE) # sampling 256 samples from the Beta distribution\n",
        "\n",
        "  zeros_onehot = torch.zeros(batch_size, NUM_CLASSES, dtype=float).to(DEVICE)\n",
        "  labels_onehot = zeros_onehot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "  # CutMix\n",
        "  image_height, image_width = labeled_images.shape[2:]\n",
        "  cut_x = np.random.uniform(0, image_width)  # return a single random value for the x cut size extremum\n",
        "  cut_y = np.random.uniform(0, image_height) # return a single random value for the y cut size extremum\n",
        "\n",
        "  cut_ratio = np.sqrt(1. - lam.numpy()) # how much to cut from the original image (batch size cut percentages)\n",
        "  cut_width = (image_width * cut_ratio).astype(int)    # width minimum for cutting the image\n",
        "  cut_height = (image_height * cut_ratio).astype(int)  # height minimum for cutting the image\n",
        "\n",
        "  x0s = np.clip(cut_x - cut_width // 2, 0, image_width).astype(int)   # initial x positions of the cut\n",
        "  x1s = np.clip(cut_x + cut_width // 2, 0, image_width).astype(int)   # final x positions of the cut\n",
        "  y0s = np.clip(cut_y - cut_height // 2, 0, image_height).astype(int) # initial y positions of the cut\n",
        "  y1s = np.clip(cut_y + cut_height // 2, 0, image_height).astype(int) # final y positions of the cut\n",
        "\n",
        "  mixed_images = copy.deepcopy(labeled_images)\n",
        "\n",
        "  for idx, (x0, x1, y0, y1) in enumerate(zip(x0s, x1s, y0s, y1s)):\n",
        "    mixed_images[idx, :, y0:y1, x0:x1] = unlabeled_images[idx, :, y0:y1, x0:x1] # take the cut box of the unlabeled img and substitute onto the labeled img\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam[idx] = 1 - ((x1 - x0) * (y1 - y0) / (labeled_images[idx].size()[-1] * labeled_images[idx].size()[-2]))\n",
        "\n",
        "  lam = lam.to(DEVICE)\n",
        "  mixed_labels = lam.view(batch_size, 1) * labels_onehot + (1 - lam).view(batch_size, 1) *  pseudo_labels # generate random mixed labels\n",
        "  mixed_indexes = torch.stack([lam, 1 - lam], dim=1).to(DEVICE) # stacked vector of the 2 lambdas for each batch (batch_num images per batch)\n",
        "\n",
        "  return mixed_images, mixed_labels, mixed_indexes\n",
        "\n",
        "\n",
        "class KL_div(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, prob, target):\n",
        "    kl = (target * torch.log((target + EPS) / (prob + EPS))).sum(1)\n",
        "    return kl.mean()\n",
        "\n",
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "  '''\n",
        "  Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "  '''\n",
        "  acc_list = []\n",
        "  for i in range(y_true.shape[0]):\n",
        "      set_true = set( np.where(y_true[i])[0] )\n",
        "      set_pred = set( np.where(y_pred[i])[0] )\n",
        "      tmp_a = None\n",
        "      if len(set_true) == 0 and len(set_pred) == 0:\n",
        "          tmp_a = 1\n",
        "      else:\n",
        "          tmp_a = len(set_true.intersection(set_pred))/float( len(set_true.union(set_pred)) )\n",
        "      acc_list.append(tmp_a)\n",
        "  return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wnn0YZIsM29",
        "colab_type": "text"
      },
      "source": [
        "**Prepare training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v_-LaCSsNgB",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def prepare_training(lr=LR, step_size=STEP_SIZE, gamma=GAMMA):\n",
        "  \n",
        "  net = ResNetFc().to(DEVICE)\n",
        "  \n",
        "  optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  criterions = {}\n",
        "  criterions['class'] = nn.CrossEntropyLoss()\n",
        "  criterions['attr'] = nn.BCELoss()\n",
        "  criterions['mixed'] = KL_div()\n",
        "\n",
        "  return net, optimizer, scheduler, criterions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im9tgi0FkToi",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smq16Uh7kVpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net, optimizer, scheduler, criterions = prepare_training()\n",
        "\n",
        "train_Ada_Net(net, dataloaders, optimizer, scheduler, criterions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE7CMnnKLqmr",
        "colab_type": "text"
      },
      "source": [
        "**Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMKpBm1FLq9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(data.dataset.Dataset):\n",
        "  def __init__(self, classes_file, transform=None):\n",
        "    self.transform = transform\n",
        "\n",
        "    class_to_index = dict()\n",
        "    # Build dictionary of indices to classes\n",
        "    with open(DATA_DIR + '/classes.txt') as f:\n",
        "      index = 0\n",
        "      for line in f:\n",
        "        class_name = line.split('\\t')[1].strip()\n",
        "        class_to_index[class_name] = index\n",
        "        index += 1\n",
        "    class_to_index['unknown'] = 50\n",
        "    self.class_to_index = class_to_index\n",
        "    img_names = []\n",
        "    img_index = []\n",
        "    \n",
        "    for key in class_to_index.keys():\n",
        "      FOLDER_DIR = os.path.join('Test', key)\n",
        "      file_descriptor = os.path.join(FOLDER_DIR, '*.jpg')\n",
        "      files = glob(file_descriptor)\n",
        "      class_index = class_to_index[key]\n",
        "      for file_name in files:\n",
        "        img_names.append(file_name)\n",
        "        img_index.append(class_index)\n",
        "    self.img_names = img_names\n",
        "    self.img_index = img_index\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    im = Image.open(self.img_names[index])\n",
        "    if im.getbands()[0] == 'L':\n",
        "      im = im.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      im = self.transform(im)\n",
        "\n",
        "    im_index = self.img_index[index]\n",
        "    return im, _, im_index\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "\n",
        "test_preprocess = transforms.Compose([\n",
        "  transforms.Resize(256), \n",
        "  transforms.CenterCrop(224),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(MEAN, STD)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma4JMBfb0LQ5",
        "colab_type": "text"
      },
      "source": [
        "**Confidence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBOZSHrgGaO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "test_preprocess = transforms.Compose([\n",
        "  transforms.Resize(256), \n",
        "  transforms.CenterCrop(224),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "unknown_dataset = TestDataset(DATA_DIR + '/classes.txt', test_preprocess)\n",
        "ood_dataloader = DataLoader(unknown_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, num_workers=4)\n",
        "\n",
        "ind_dataloader = dataloaders['ind_dataloader']\n",
        "\n",
        "def tpr95(ind_confidences, ood_confidences):\n",
        "    #calculate the falsepositive error when tpr is 95%\n",
        "    Y1 = ood_confidences\n",
        "    X1 = ind_confidences\n",
        "\n",
        "    start = np.min([np.min(X1), np.min(Y1)])\n",
        "    end = np.max([np.max(X1), np.max(Y1)])\n",
        "    gap = (end - start) / 100000\n",
        "\n",
        "    total = 0.0\n",
        "    fpr = 0.0\n",
        "    for delta in np.arange(start, end, gap):\n",
        "        tpr = np.sum(np.sum(X1 >= delta)) / np.float(len(X1))\n",
        "        error2 = np.sum(np.sum(Y1 > delta)) / np.float(len(Y1))\n",
        "        if tpr <= 0.9505 and tpr >= 0.9495:\n",
        "            fpr += error2\n",
        "            total += 1\n",
        "\n",
        "    fprBase = fpr / total\n",
        "\n",
        "    return fprBase\n",
        "\n",
        "def detection(ind_confidences, ood_confidences, n_iter=100000, return_data=False):\n",
        "    # calculate the minimum detection error\n",
        "    Y1 = ood_confidences\n",
        "    X1 = ind_confidences\n",
        "\n",
        "    start = np.min([np.min(X1), np.min(Y1)])\n",
        "    end = np.max([np.max(X1), np.max(Y1)])\n",
        "    gap = (end - start) / n_iter\n",
        "\n",
        "    best_error = 1.0\n",
        "    best_delta = None\n",
        "    all_thresholds = []\n",
        "    all_errors = []\n",
        "    for delta in np.arange(start, end, gap):\n",
        "        tpr = np.sum(np.sum(X1 < delta)) / np.float(len(X1))\n",
        "        error2 = np.sum(np.sum(Y1 > delta)) / np.float(len(Y1))\n",
        "        detection_error = (tpr + error2) / 2.0\n",
        "\n",
        "        if return_data:\n",
        "            all_thresholds.append(delta)\n",
        "            all_errors.append(detection_error)\n",
        "\n",
        "        if detection_error < best_error:\n",
        "            best_error = np.minimum(best_error, detection_error)\n",
        "            best_delta = delta\n",
        "\n",
        "    if return_data:\n",
        "        return best_error, best_delta, all_errors, all_thresholds\n",
        "    else:\n",
        "        return best_error, best_delta\n",
        "\n",
        "def evaluate(model, dataloader, T, eps):\n",
        "  out = []\n",
        "  for data in tqdm(dataloader, position=0, leave=True):\n",
        "    if len(data) == 3:\n",
        "      images, _, _ = data\n",
        "    else:\n",
        "      images, _ = data\n",
        "\n",
        "    images = Variable(images, requires_grad=True).to(DEVICE)\n",
        "    images.retain_grad()\n",
        "\n",
        "    model.zero_grad()\n",
        "    pred, _, _ = model(images)\n",
        "    _, pred_idx = torch.max(pred.data, 1)\n",
        "    labels = Variable(pred_idx)\n",
        "    pred = pred / T\n",
        "    loss = criterion(pred, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    images = images - eps * torch.sign(images.grad)\n",
        "    images = Variable(images.data, requires_grad=True)\n",
        "\n",
        "    pred, _, _ = model(images)\n",
        "    output = pred\n",
        "\n",
        "    pred = pred / T\n",
        "    pred = F.softmax(pred, dim=-1)\n",
        "\n",
        "    pred = torch.max(pred.data, 1)[0]\n",
        "\n",
        "    pred = pred.cpu().numpy()\n",
        "    \n",
        "    out.append(pred)\n",
        "\n",
        "  out = np.concatenate(out)\n",
        "  return out\n",
        "\n",
        "# GRID SEARCH\n",
        "\n",
        "temperatures = np.linspace(1.23, 1.45, 12)\n",
        "#epsilons = [0, 0.002, 0.004, 0.006]\n",
        "epsilons = [0]\n",
        "best_error = 1000.0\n",
        "\n",
        "for T in temperatures:\n",
        "  model = ResNetFc().to(DEVICE)\n",
        "  checkpoint = torch.load(PATH_BEST)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  model.eval()\n",
        "  for eps in epsilons:\n",
        "    print('\\nT = {}, eps = {}'.format(T, eps), flush=True)\n",
        "    print('Evaluation of ind_dataset...', flush=True)\n",
        "    ind_scores = evaluate(model, ind_dataloader, T, eps)\n",
        "    ind_labels = np.ones(ind_scores.shape[0])\n",
        "    print('\\nEvaluation of ood_dataset...', flush=True)\n",
        "    ood_scores = evaluate(model, ood_dataloader, T, eps)\n",
        "    ood_labels = np.zeros(ood_scores.shape[0])\n",
        "\n",
        "    labels = np.concatenate([ind_labels, ood_labels])\n",
        "    scores = np.concatenate([ind_scores, ood_scores])\n",
        "\n",
        "    fpr, tpr, threshold = metrics.roc_curve(labels, scores)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "    fpr_at_95_tpr = tpr95(ind_scores, ood_scores)\n",
        "    detection_error, best_delta = detection(ind_scores, ood_scores)\n",
        "\n",
        "    if detection_error<best_error:\n",
        "      best_error = detection_error\n",
        "      best_eps = eps\n",
        "      best_temp = T\n",
        "\n",
        "    auroc = metrics.roc_auc_score(labels, scores)\n",
        "    aupr_in = metrics.average_precision_score(labels, scores)\n",
        "    aupr_out = metrics.average_precision_score(-1 * labels + 1, 1 - scores)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"TPR95 (lower is better): \", fpr_at_95_tpr)\n",
        "    print(\"Detection error (lower is better): \", detection_error)\n",
        "    print(\"Best threshold:\", best_delta)\n",
        "    print(\"AUROC (higher is better): \", auroc)\n",
        "    print(\"AUPR_IN (higher is better): \", aupr_in)\n",
        "    print(\"AUPR_OUT (higher is better): \", aupr_out)\n",
        "\n",
        "    ranges = (np.min(scores), np.max(scores))\n",
        "    plt.figure()\n",
        "    sns.distplot(ind_scores.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='In-distribution')\n",
        "    sns.distplot(ood_scores.ravel(), hist_kws={'range': ranges}, kde=False, bins=50, norm_hist=True, label='Out-of-distribution')\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.ylabel('Density')\n",
        "    plt.xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "765H3mZ3HPR9",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSIDNwhL0OHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_out(model, dataloader, T, eps, threshold):\n",
        "\n",
        "  out = []\n",
        "  running_corrects = 0\n",
        "  errors = 0\n",
        "\n",
        "  for images, _, _labels in tqdm(dataloader, position=0, leave=True):\n",
        "    \n",
        "    images = Variable(images, requires_grad=True).to(DEVICE)\n",
        "    images.retain_grad()\n",
        "\n",
        "    model.zero_grad()\n",
        "    pred_labels, pred_attributes, _ = model(images)\n",
        "    _, pred_idx = torch.max(pred_labels.data, 1)\n",
        "    labels = Variable(pred_idx)\n",
        "    pred_labels = pred_labels / T\n",
        "    loss = criterions['class'](pred_labels, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    images = images - eps * torch.sign(images.grad)\n",
        "    images = Variable(images.data, requires_grad=True)\n",
        "\n",
        "    pred_labels, _, _ = model(images)\n",
        "\n",
        "    pred_labels = pred_labels / T\n",
        "    pred_labels = F.softmax(pred_labels, dim=-1)\n",
        "\n",
        "    for i in range(len(pred_labels)):\n",
        "      pred_label = pred_labels[i]\n",
        "      pred_attribute = pred_attributes[i]\n",
        "      true_label = _labels[i]\n",
        "    \n",
        "      if(true_label == 50):\n",
        "        #Here we have an out of distribution sample\n",
        "        print('There is an out of distribution sample.')\n",
        "        if (pred_label.max() < threshold):\n",
        "          running_corrects += 1\n",
        "          top5 = torch.topk(pred_label, 5)\n",
        "          values_labels = top5.values\n",
        "          indices_labels = top5.indices                    \n",
        "          imshow(images[i].detach().cpu())\n",
        "             \n",
        "          attr_outputs = (torch.sigmoid(pred_attribute) > 0.5).float()\n",
        "          top85 = torch.topk(torch.sigmoid(pred_attribute), 85)\n",
        "          attributes_found = []\n",
        "          attributes_found_indices = []\n",
        "          for z in range(85):\n",
        "            if predicate_binary_mat[indices_labels[0].item()][z] == 0 and attr_outputs[z] == 1:\n",
        "              attributes_found_indices.append(z)\n",
        "          values_attributes = top85.values\n",
        "          indices_attributes = top85.indices\n",
        "          first = 0\n",
        "          if not attributes_found_indices:\n",
        "            most_attribute = 'strange'\n",
        "          else:\n",
        "            for i in range(85):\n",
        "              for j in attributes_found_indices:\n",
        "                if indices_attributes[i].item()==j:\n",
        "                  if first == 0:\n",
        "                    most_attribute = predicates[j]\n",
        "                    first = 1\n",
        "          print('New class found: {} {}.'.format(most_attribute, classes[indices_labels[0].item()]))\n",
        "        else:\n",
        "          errors += 1\n",
        "      else:\n",
        "        print('There is an in of distribution sample.')\n",
        "        if (pred_label.max() < threshold):\n",
        "          errors +=1\n",
        "        else:\n",
        "          _, preds = torch.max(pred_label.data, -1)\n",
        "          if preds.item() == true_label.item():\n",
        "            running_corrects +=1       \n",
        "  return running_corrects, errors\n",
        "\n",
        "model = net\n",
        "if Path(PATH_BEST).exists():\n",
        "  best_accuracy = load_checkpoint('last', model, optimizer)\n",
        "model.eval()\n",
        "\n",
        "unknown_dataset = TestDataset(DATA_DIR + '/classes.txt', test_preprocess)\n",
        "test_dataset = unknown_dataset + ind_dataset\n",
        "print('Length dataset: {}'.format(len(test_dataset)))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# TEST PARAMETERS AFTER GRID SEARCH\n",
        "\n",
        "T = 1.4\n",
        "eps = 0.0\n",
        "threshold = 0.50\n",
        "\n",
        "corrects, errors = test_out(model, test_dataloader, T, eps, threshold)\n",
        "\n",
        "total = len(test_dataloader.dataset)\n",
        "\n",
        "print('Accuracy: {:.4f}'.format(corrects / total))\n",
        "print('Errors: [{}/{}]'.format(errors, total))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}